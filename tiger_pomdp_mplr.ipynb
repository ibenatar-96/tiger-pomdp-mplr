{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEbcqe1ydkehCXeRqC6h1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibenatar-96/tiger-pomdp-mplr/blob/main/tiger_pomdp_mplr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlRt7K6iURrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb20b27e-18b6-4940-d5ed-74a1adb5bfbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpyro\n",
            "  Downloading numpyro-0.14.0-py3-none-any.whl (330 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/330.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m235.5/330.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/330.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.2/330.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from numpyro) (0.4.26)\n",
            "Requirement already satisfied: jaxlib>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from numpyro) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from numpyro) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from numpyro) (4.66.4)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (1.11.4)\n",
            "Installing collected packages: numpyro\n",
            "Successfully installed numpyro-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpyro"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "import numpyro.distributions.constraints as constraints\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "from itertools import product\n",
        "\n",
        "numpyro.set_host_device_count(4)"
      ],
      "metadata": {
        "id": "aR903yFhUjUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiger POMDP (Partially Observable Markov Decision Process)\n",
        "\n",
        "The Tiger POMDP is a classical problem in the field of artificial intelligence and decision-making under uncertainty. It's used to illustrate the challenges of decision-making when there's uncertainty about the state of the environment.\n",
        "\n",
        "In the Tiger POMDP scenario, an agent is placed in a room with two doors. Behind one door is his freedom, and behind the other is a tiger. The agent doesn't know which door leads to which outcome. It can take actions like \"listen\" to hear a sound indicating the location of the tiger or \"open\" a door to reveal its contents. However, actions are imperfect, leading to uncertainty.\n",
        "\n",
        "Solving the Tiger POMDP involves finding a policy that maximizes the expected cumulative reward over time, taking into account the uncertainty and partial observability. Various algorithms, such as belief state planning or particle filtering, can be used to approximate or solve POMDPs.\n",
        "\n",
        "The Tiger POMDP can be represented as a Partially Observable Markov Decision Process (POMDP) defined by the tuple $(S, A, T, R, Ω, O, γ)$, where:\n",
        "\n",
        "\\\\\n",
        "$S$: The finite set of states consists of two elements representing the locations of the tiger and his freedom.\n",
        "\n",
        "$A$: The finite set of actions available to the agent includes \"listen\" and \"open\" representing actions to gather information or make decisions.\n",
        "\n",
        "$T$: The state transition function $T: S \\times A \\mapsto S$ describes the transition probabilities between states based on actions. For example, if the agent decides to \"open\" a door, the state transition function will determine the probabilities of transitioning to either the tiger or freedom state.\n",
        "\n",
        "$R$: The reward function $R: S \\times A \\mapsto \\mathbb{R}$ provides immediate rewards for actions in specific states. For instance, opening the door containing his freedom could yield a positive reward, while opening the door with the tiger will result in a negative reward.\n",
        "\n",
        "$Ω$: The finite set of observations consists of two elements representing the possible observations of \"tiger-left\" and \"tiger-right\" when the agent chooses to \"listen\".\n",
        "\n",
        "$O$: The set of conditional observation probabilities $Ω$ specifies the likelihood of observing each possible observation given the true state of the environment.\n",
        "\n",
        "$γ$: The discount factor $γ \\in [0,1]$ accounts for the importance of future rewards relative to immediate rewards in the agent's decision-making process."
      ],
      "metadata": {
        "id": "djPxfC9JAv2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating \"Synthetic\" Observations.\n",
        "\n",
        "Now let's create synthetic observations / data for our model to learn from.\n",
        "\n",
        "This synthetic data is following the rules of the original Tiger POMDP problem,\n",
        "where the probability of getting a correct observation when doing \"listen\" action is 0.85.\n",
        "\n",
        "Our observations will be in the form of a list that consists of episodes:\n",
        "\n",
        "$b_{0},(a_{0},o_{0}),(a_{1},o_{1}),...,(,a_{n},o_{n})$\n",
        "\n",
        "Where $(a_{t},o_{t})$ -\n",
        "\n",
        "$a_{t}$ - the action taken in time step $t$\n",
        "\n",
        "$o_{t}$ - the observation recieved at time step $t$\n",
        "\n",
        "$\\Omega = \\{o_{tl}, o_{tr}\\} $\n",
        "\n",
        "Where $O(s',a,o) = P(o_{tl}|s',a_{listen}) = P(o_{tr}|s',a_{listen}) =\n",
        "\\begin{align}\n",
        "     \\left\\{\n",
        "        \\begin{array}{cl}\n",
        "        0.85 & \\text{if s' == s}  \\\\\n",
        "        0.15 & \\text{if s' != s}\n",
        "        \\end{array}\n",
        "    \\right.\n",
        "\\end{align}$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$O(s'_{tl},a_{listen},o_{tl}) = 0.85$\n",
        "\n",
        "$O(s'_{tl},a_{listen},o_{tr}) = 0.15$\n",
        "\n",
        "$O(s'_{tr},a_{listen},o_{tl}) = 0.15$\n",
        "\n",
        "$O(s'_{tr},a_{listen},o_{tr}) = 0.85$\n",
        "\n",
        "\n",
        "The context here of s' is that I have \"reached\" the state that the action took me to.\n",
        "Meaning - for example, we know that $a_{listen}$ keeps us in the same state, so if the real tiger location is behind the left door - acting $a_{listen}$ will result in s' = \"tiger-left\", and the probability of observing $o_{tl}$ is 0.85, and the probability of observing $o_{tr}$ is 0.15.\n",
        "\n",
        "* When action $a$ is \"open-left\" or \"open-right\", then recieving $o_{tl}$ and $o_{tr}$ are evenly distributed (uniformly).\n",
        "\n",
        "Explanation - Observing the correct state occurs with probability 0.85, for example when the state is $s_{tl}$ (meaning the tiger is behind the left door), we will recieve the correct observation - $o_{tl}$ (that the tiger is behind the left door) with probability 0.85, and we will recieve the incorrect observation - $o_{tr}$ with probability 0.15."
      ],
      "metadata": {
        "id": "rDPSH93nD92B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Actions = [\"listen\", \"open-left\", \"open-right\"]\n",
        "States = [\"tiger-left\", \"tiger-right\"]\n",
        "Observations = [\"tiger-left\", \"tiger-right\"]\n",
        "Inital_Belief_State = {\"tiger-left\": 0.5, \"tiger-right\": 0.5}\n",
        "Terminate_Actions = [\"open-left\", \"open-right\"]\n",
        "\n",
        "# Observation Model: {(state-prime, action): {observation1: probability1, observation2: probability2}}\n",
        "Observation_Model = {(\"tiger-left\",\"listen\"): {\"tiger-left\": 0.85,\n",
        "                                               \"tiger-right\": 0.15},\n",
        "                     (\"tiger-right\",\"listen\"): {\"tiger-left\": 0.15,\n",
        "                                                \"tiger-right\":0.85},\n",
        "                     (\"tiger-left\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-left\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5}}\n",
        "\n",
        "# Transition Model: {(state, action): {state-prime1: probability1, state-prime2: probability2}}\n",
        "Transition_Model = {(\"tiger-left\",\"listen\"): {\"tiger-left\": 1.0,\n",
        "                                               \"tiger-right\": 0.0},\n",
        "                     (\"tiger-right\",\"listen\"): {\"tiger-left\": 0.0,\n",
        "                                                \"tiger-right\":1.0},\n",
        "                     (\"tiger-left\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-left\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5}}"
      ],
      "metadata": {
        "id": "kUjXa_F4Q19q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_obs(mode='random'):\n",
        "    episodes_obs = []\n",
        "    for _ in range(15): # create 15 episodes\n",
        "        episode_log = [np.array([0.5,0.5])]\n",
        "        action = None\n",
        "        tiger_state = np.random.choice(States, size=None)\n",
        "        if tiger_state == \"tiger-left\":\n",
        "            obs_prob = [0.85, 0.15]\n",
        "        else:\n",
        "            obs_prob = [0.15, 0.85]\n",
        "        if mode == 'simple':\n",
        "            action_cnt = 0\n",
        "        while action not in Terminate_Actions:\n",
        "            if mode == 'random':\n",
        "                action = np.random.choice(Actions, size=None, p=[0.5,0.25,0.25])\n",
        "            elif mode == 'simple':\n",
        "                if action_cnt == 0:\n",
        "                    action = 'listen'\n",
        "                else:\n",
        "                    action = np.random.choice([a for a in Actions if a.startswith(\"open\")], size=None)\n",
        "                action_cnt += 1\n",
        "            assert action is not None\n",
        "            if action == \"listen\":\n",
        "                obs = np.random.choice(Observations, size=None, p=obs_prob)\n",
        "            else:\n",
        "                obs = np.random.choice(Observations, size=None, p=[1 if state == tiger_state else 0 for state in States])\n",
        "            episode_log.append((action, obs))\n",
        "        episodes_obs.append(episode_log)\n",
        "    return episodes_obs"
      ],
      "metadata": {
        "id": "k3R6EgqwDMFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observations = gen_obs()\n",
        "for i,obs in enumerate(observations):\n",
        "    print(f\"obs[{i}] = {obs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAhPOnWPqZIv",
        "outputId": "c8b84738-ac97-4c5c-9eea-549194fabf83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs[0] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[1] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[2] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-left', {'tiger-left': 0.85, 'tiger-right': 0.15}), ({'tiger-left': 0.85, 'tiger-right': 0.15}, 'listen', 'tiger-left', {'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}), ({'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[3] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5}), ({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[4] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[5] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[6] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-right', {'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}), ({'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}, 'listen', 'tiger-right', {'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}), ({'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}, 'listen', 'tiger-right', {'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}), ({'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[7] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[8] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-left', {'tiger-left': 0.85, 'tiger-right': 0.15}), ({'tiger-left': 0.85, 'tiger-right': 0.15}, 'listen', 'tiger-left', {'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}), ({'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}, 'listen', 'tiger-left', {'tiger-left': 0.9945344129554656, 'tiger-right': 0.005465587044534414}), ({'tiger-left': 0.9945344129554656, 'tiger-right': 0.005465587044534414}, 'open-right', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[9] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-right', {'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}), ({'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}, 'listen', 'tiger-right', {'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}), ({'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}, 'listen', 'tiger-right', {'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}), ({'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}, 'listen', 'tiger-right', {'tiger-left': 0.00017111471023167384, 'tiger-right': 0.9998288852897683}), ({'tiger-left': 0.00017111471023167384, 'tiger-right': 0.9998288852897683}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[10] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5}), ({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[11] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[12] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[13] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[14] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-left', {'tiger-left': 0.85, 'tiger-right': 0.15}), ({'tiger-left': 0.85, 'tiger-right': 0.15}, 'listen', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5}), ({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tiger_model(obs=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    obs: observations - logs of episodes.\n",
        "    obs is a lists of lists (list of episode logs), [[...], [...], [...]],\n",
        "    each list in the obs list contains: [belief-state_0, (action_0, observation_0),\n",
        "                                                         (action_1, observation_1),\n",
        "                                         ...,\n",
        "                                                         (action_n, observation_n)]\n",
        "    \"\"\"\n",
        "    p_observations = {}\n",
        "    for state_prime,action in product(States, Actions):\n",
        "        p_observations[(state_prime,action)] = {}\n",
        "        for o in Observation_Model:\n",
        "            p_observations[(state_prime,action)][o] = numpyro.sample(f\"O({o},{action},{state_prime})\") # Probability of seeing observation 'o', after doing action 'a' and reaching s'.\n",
        "\n",
        "    if obs is not None:\n",
        "        observations_arr = jnp.array([[Observation_Model[(sp, action)][observation] for sp in States] for o[1:] in obs for _, _, observation, belief_state_prime in o])\n"
      ],
      "metadata": {
        "id": "MLkR5usprsMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpyro.render_model(tiger_model, model_args=(observations,), render_distributions=True, render_params=True,)"
      ],
      "metadata": {
        "id": "KLYDcyPCdRqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(ai_model, obs):\n",
        "    nuts_kernel = numpyro.infer.NUTS(ai_model)\n",
        "    mcmc = numpyro.infer.MCMC(\n",
        "        nuts_kernel,\n",
        "        num_warmup=500,\n",
        "        num_chains=4,\n",
        "        num_samples=5000)\n",
        "    mcmc.run(jax.random.PRNGKey(int(time.time() * 1E6)), obs=obs)\n",
        "    mcmc.print_summary()\n",
        "    return mcmc"
      ],
      "metadata": {
        "id": "o7n-4QuvQSzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(tiger_model, observations)"
      ],
      "metadata": {
        "id": "G4W0q4p5Qajy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}