{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6mQmPMvVycEu4Q/CvUV+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibenatar-96/tiger-pomdp-mplr/blob/main/tiger_pomdp_mplr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlRt7K6iURrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb20b27e-18b6-4940-d5ed-74a1adb5bfbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpyro\n",
            "  Downloading numpyro-0.14.0-py3-none-any.whl (330 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/330.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m235.5/330.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/330.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.2/330.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from numpyro) (0.4.26)\n",
            "Requirement already satisfied: jaxlib>=0.4.14 in /usr/local/lib/python3.10/dist-packages (from numpyro) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from numpyro) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from numpyro) (4.66.4)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.14->numpyro) (1.11.4)\n",
            "Installing collected packages: numpyro\n",
            "Successfully installed numpyro-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpyro"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "import numpyro.distributions.constraints as constraints\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "from itertools import product\n",
        "\n",
        "numpyro.set_host_device_count(4)"
      ],
      "metadata": {
        "id": "aR903yFhUjUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiger POMDP (Partially Observable Markov Decision Process)\n",
        "\n",
        "The Tiger POMDP is a classical problem in the field of artificial intelligence and decision-making under uncertainty. It's used to illustrate the challenges of decision-making when there's uncertainty about the state of the environment.\n",
        "\n",
        "In the Tiger POMDP scenario, an agent is placed in a room with two doors. Behind one door is his freedom, and behind the other is a tiger. The agent doesn't know which door leads to which outcome. It can take actions like \"listen\" to hear a sound indicating the location of the tiger or \"open\" a door to reveal its contents. However, actions are imperfect, leading to uncertainty.\n",
        "\n",
        "Solving the Tiger POMDP involves finding a policy that maximizes the expected cumulative reward over time, taking into account the uncertainty and partial observability. Various algorithms, such as belief state planning or particle filtering, can be used to approximate or solve POMDPs.\n",
        "\n",
        "The Tiger POMDP can be represented as a Partially Observable Markov Decision Process (POMDP) defined by the tuple $(S, A, T, R, Ω, O, γ)$, where:\n",
        "\n",
        "\\\\\n",
        "$S$: The finite set of states consists of two elements representing the locations of the tiger and his freedom.\n",
        "\n",
        "$A$: The finite set of actions available to the agent includes \"listen\" and \"open\" representing actions to gather information or make decisions.\n",
        "\n",
        "$T$: The state transition function $T: S \\times A \\mapsto S$ describes the transition probabilities between states based on actions. For example, if the agent decides to \"open\" a door, the state transition function will determine the probabilities of transitioning to either the tiger or freedom state.\n",
        "\n",
        "$R$: The reward function $R: S \\times A \\mapsto \\mathbb{R}$ provides immediate rewards for actions in specific states. For instance, opening the door containing his freedom could yield a positive reward, while opening the door with the tiger will result in a negative reward.\n",
        "\n",
        "$Ω$: The finite set of observations consists of two elements representing the possible observations of \"tiger-left\" and \"tiger-right\" when the agent chooses to \"listen\".\n",
        "\n",
        "$O$: The set of conditional observation probabilities $Ω$ specifies the likelihood of observing each possible observation given the true state of the environment.\n",
        "\n",
        "$γ$: The discount factor $γ \\in [0,1]$ accounts for the importance of future rewards relative to immediate rewards in the agent's decision-making process."
      ],
      "metadata": {
        "id": "djPxfC9JAv2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating \"Synthetic\" Observations.\n",
        "\n",
        "Now let's create synthetic observations / data for our model to learn from.\n",
        "\n",
        "This synthetic data is following the rules of the original Tiger POMDP problem,\n",
        "where the probability of getting a correct observation when doing \"listen\" action is 0.85.\n",
        "\n",
        "Our observations will be in the form of a list that consists of episodes:\n",
        "\n",
        "$(b_{0},a_{0},o_{0},b_{1}),(b_{1},a_{1},o_{1},b_{2}),...,(b_{n-1},a_{n-1},o_{n-1},b_{n})$\n",
        "\n",
        "Where $(b_{t},a_{t},o_{t},b_{t+1})$ -\n",
        "\n",
        "$b_{t}$ - the belief state of time step $t$\n",
        "\n",
        "$a_{t}$ - the action taken in time step $t$\n",
        "\n",
        "$o_{t}$ - the observation recieved at time step $t$\n",
        "\n",
        "$b_{1}$ - the updated belief state at time step $t+1$\n",
        "\n",
        "We will use $b^{a}_{o}(s')=P(s'|o,a,b)=\\frac{O(s'a,o)*\\sum_{s\\in S}Tr(s,a,s')*b(s)}{P(o|a,b)}$ to update our belief state.\n",
        "\n",
        "$\\Omega = \\{o_{tl}, o_{tr}\\} $\n",
        "\n",
        "Where $O(s',a,o) = P(o_{tl}|s',a_{listen}) = P(o_{tr}|s',a_{listen}) =\n",
        "\\begin{align}\n",
        "     \\left\\{\n",
        "        \\begin{array}{cl}\n",
        "        0.85 & \\text{if s' == s}  \\\\\n",
        "        0.15 & \\text{if s' != s}\n",
        "        \\end{array}\n",
        "    \\right.\n",
        "\\end{align}$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$O(s'_{tl},a_{listen},o_{tl}) = 0.85$\n",
        "\n",
        "$O(s'_{tl},a_{listen},o_{tr}) = 0.15$\n",
        "\n",
        "$O(s'_{tr},a_{listen},o_{tl}) = 0.15$\n",
        "\n",
        "$O(s'_{tr},a_{listen},o_{tr}) = 0.85$\n",
        "\n",
        "\n",
        "The context here of s' is that I have \"reached\" the state that the action took me to.\n",
        "Meaning - for example, we know that $a_{listen}$ keeps us in the same state, so if the real tiger location is behind the left door - acting $a_{listen}$ will result in s' = \"tiger-left\", and the probability of observing $o_{tl}$ is 0.85, and the probability of observing $o_{tr}$ is 0.15.\n",
        "\n",
        "* When action $a$ is \"open-left\" or \"open-right\", then recieving $o_{tl}$ and $o_{tr}$ are evenly distributed (uniformly).\n",
        "\n",
        "Explanation - Observing the correct state occurs with probability 0.85, for example when the state is $s_{tl}$ (meaning the tiger is behind the left door), we will recieve the correct observation - $o_{tl}$ (that the tiger is behind the left door) with probability 0.85, and we will recieve the incorrect observation - $o_{tr}$ with probability 0.15.\n",
        "\n",
        "$\\text{Transition Model T(s,a,s')}$\n",
        "\n",
        "$T(s,a,s') =\n",
        "\\begin{align}\n",
        "     \\left\\{\n",
        "        \\begin{array}{cl}\n",
        "        1 & \\text{if s' == s & a = listen}  \\\\\n",
        "        0 & \\text{if s' != s & a = listen}  \\\\\n",
        "        0.5 & \\text{if a = open-left | open-right}\n",
        "        \\end{array}\n",
        "    \\right.\n",
        "\\end{align}$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$T(s_{tl},a_{listen},s'_{tl}) = T(s_{tr},a_{listen},s'_{tr}) = 1$\n",
        "\n",
        "$T(s_{tl},a_{listen},s'_{tr}) = T(s_{tr},a_{listen},s'_{tl}) = 0$\n",
        "\n",
        "$T(s_{tl},a_{open-left},s'_{tl}) = T(s_{tl},a_{open-left},s'_{tr}) = 0.5$\n",
        "\n",
        "$T(s_{tr},a_{open-left},s'_{tl}) = T(s_{tr},a_{open-left},s'_{tr}) = 0.5$\n",
        "\n",
        "$T(s_{tl},a_{open-right},s'_{tl}) = T(s_{tl},a_{open-right},s'_{tr}) = 0.5$\n",
        "\n",
        "$T(s_{tr},a_{open-right},s'_{tl}) = T(s_{tr},a_{open-left},s'_{tr}) = 0.5$\n",
        "\n",
        "\n",
        "Explanation - When doing a \"listen\" action, the state stays the same; and when doing a \"open\" action (open-left or open-right) the world is reset and the probability to transition to $s_{tl}$ and $s_{tr}$ is uniformly distributed."
      ],
      "metadata": {
        "id": "rDPSH93nD92B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Actions = [\"listen\", \"open-left\", \"open-right\"]\n",
        "States = [\"tiger-left\", \"tiger-right\"]\n",
        "Observations = [\"tiger-left\", \"tiger-right\"]\n",
        "Inital_Belief_State = {\"tiger-left\": 0.5, \"tiger-right\": 0.5}\n",
        "Terminate_Actions = [\"open-left\", \"open-right\"]\n",
        "\n",
        "# Observation Model: {(state-prime, action): {observation1: probability1, observation2: probability2}}\n",
        "Observation_Model = {(\"tiger-left\",\"listen\"): {\"tiger-left\": 0.85,\n",
        "                                               \"tiger-right\": 0.15},\n",
        "                     (\"tiger-right\",\"listen\"): {\"tiger-left\": 0.15,\n",
        "                                                \"tiger-right\":0.85},\n",
        "                     (\"tiger-left\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-left\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5}}\n",
        "\n",
        "# Transition Model: {(state, action): {state-prime1: probability1, state-prime2: probability2}}\n",
        "Transition_Model = {(\"tiger-left\",\"listen\"): {\"tiger-left\": 1.0,\n",
        "                                               \"tiger-right\": 0.0},\n",
        "                     (\"tiger-right\",\"listen\"): {\"tiger-left\": 0.0,\n",
        "                                                \"tiger-right\":1.0},\n",
        "                     (\"tiger-left\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-left\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-left\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5},\n",
        "                     (\"tiger-right\",\"open-right\"): {\"tiger-right\":0.5,\n",
        "                                                   \"tiger-left\":0.5}}"
      ],
      "metadata": {
        "id": "kUjXa_F4Q19q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_next_bs(observation, action, state, belief_state):\n",
        "    b_s = {}\n",
        "    for state_prime in States:\n",
        "        obs_prob = Observation_Model[(state_prime,action)][observation]\n",
        "        prob_unfactored = 0.0\n",
        "        for state, prob in belief_state.items():\n",
        "            prob_unfactored += (Transition_Model[(state, action)][state_prime] * prob)\n",
        "        b_s[state_prime] = obs_prob * prob_unfactored\n",
        "    norm_factor = sum(b_s.values())\n",
        "    norm_b_s = {key: value / norm_factor for key, value in b_s.items()} # Normalizing the Belief State\n",
        "    return norm_b_s\n",
        "\n",
        "def gen_obs():\n",
        "    episodes_obs = []\n",
        "    for _ in range(15): # create 15 episodes\n",
        "        episode_log = []\n",
        "        action = None\n",
        "        tiger_state = np.random.choice(States, size=None)\n",
        "        belief_state = Inital_Belief_State\n",
        "        if tiger_state == \"tiger-left\":\n",
        "            obs_prob = [0.85, 0.15]\n",
        "        else:\n",
        "            obs_prob = [0.15, 0.85]\n",
        "        state = tiger_state\n",
        "        while action not in Terminate_Actions:\n",
        "            action = np.random.choice(Actions, size=None, p=[0.5,0.25,0.25])\n",
        "            if action == \"listen\":\n",
        "                obs = np.random.choice(Observations, size=None, p=obs_prob)\n",
        "            else:\n",
        "                obs = np.random.choice(Observations, size=None)\n",
        "            # next_state = np.random.choice(list(Transition_Model[(state,action)].keys()), size=None, p=list(Transition_Model[(state,action)].values()))\n",
        "            next_belief_state = calc_next_bs(obs, action, state, belief_state)\n",
        "            episode_log.append((belief_state, action, obs, next_belief_state))\n",
        "            belief_state = next_belief_state\n",
        "        episodes_obs.append(episode_log)\n",
        "    return episodes_obs"
      ],
      "metadata": {
        "id": "k3R6EgqwDMFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observations = gen_obs()\n",
        "for i,obs in enumerate(observations):\n",
        "    print(f\"obs[{i}] = {obs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAhPOnWPqZIv",
        "outputId": "c8b84738-ac97-4c5c-9eea-549194fabf83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs[0] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[1] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[2] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-left', {'tiger-left': 0.85, 'tiger-right': 0.15}), ({'tiger-left': 0.85, 'tiger-right': 0.15}, 'listen', 'tiger-left', {'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}), ({'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[3] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5}), ({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[4] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[5] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[6] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-right', {'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}), ({'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}, 'listen', 'tiger-right', {'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}), ({'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}, 'listen', 'tiger-right', {'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}), ({'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[7] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[8] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-left', {'tiger-left': 0.85, 'tiger-right': 0.15}), ({'tiger-left': 0.85, 'tiger-right': 0.15}, 'listen', 'tiger-left', {'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}), ({'tiger-left': 0.9697986577181208, 'tiger-right': 0.0302013422818792}, 'listen', 'tiger-left', {'tiger-left': 0.9945344129554656, 'tiger-right': 0.005465587044534414}), ({'tiger-left': 0.9945344129554656, 'tiger-right': 0.005465587044534414}, 'open-right', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[9] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-right', {'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}), ({'tiger-left': 0.0302013422818792, 'tiger-right': 0.9697986577181208}, 'listen', 'tiger-right', {'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}), ({'tiger-left': 0.005465587044534414, 'tiger-right': 0.9945344129554656}, 'listen', 'tiger-right', {'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}), ({'tiger-left': 0.0009688763426712281, 'tiger-right': 0.9990311236573287}, 'listen', 'tiger-right', {'tiger-left': 0.00017111471023167384, 'tiger-right': 0.9998288852897683}), ({'tiger-left': 0.00017111471023167384, 'tiger-right': 0.9998288852897683}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[10] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'listen', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5}), ({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[11] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-right', {'tiger-left': 0.15, 'tiger-right': 0.85}), ({'tiger-left': 0.15, 'tiger-right': 0.85}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[12] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[13] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-left', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n",
            "obs[14] = [({'tiger-left': 0.5, 'tiger-right': 0.5}, 'listen', 'tiger-left', {'tiger-left': 0.85, 'tiger-right': 0.15}), ({'tiger-left': 0.85, 'tiger-right': 0.15}, 'listen', 'tiger-right', {'tiger-left': 0.5, 'tiger-right': 0.5}), ({'tiger-left': 0.5, 'tiger-right': 0.5}, 'open-right', 'tiger-left', {'tiger-left': 0.5, 'tiger-right': 0.5})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_belief_state_general(noise, obs_prob, transition_prob, belief_state):\n",
        "    b_s = {}\n",
        "    for state_prime in States:\n",
        "        prob_unfactored = 0.0\n",
        "        for state, prob in belief_state.items():\n",
        "            prob_unfactored += (transition_prob * prob)\n",
        "        b_s[state_prime] = obs_prob * prob_unfactored\n",
        "    norm_factor = sum(b_s.values())\n",
        "    norm_b_s = {key: value / norm_factor for key, value in b_s.items()} # Normalizing the Belief State\n",
        "    return norm_b_s"
      ],
      "metadata": {
        "id": "MLkR5usprsMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_belief_state_transition(action, p_observation, transition_prob, belief_state, belief_state_prime):\n",
        "    bs_prime = p_observation * jnp.dot(transition_prob, belief_state)\n",
        "    normalized_bs_prime = bs_prime / jnp.sum(bs_prime)\n",
        "    accuracy = jnp.all(jnp.abs(normalized_bs_prime - belief_state_prime) <= 0.1) & (jnp.shape(normalized_bs_prime)[0] == jnp.shape(belief_state_prime)[0])\n",
        "    return normalized_bs_prime, accuracy"
      ],
      "metadata": {
        "id": "N74j-91IW1HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tiger_model_transition(obs=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    obs: observations - logs of episodes.\n",
        "    obs is a lists of lists (list of episode logs), [[...], [...], [...]],\n",
        "    each list in the obs list contains: [(belief-state_0, action_0, observation_0, belief-state_1),\n",
        "                                         (belief-state_1, action_1, observation_1, belief-state_2),\n",
        "                                         ...,\n",
        "                                         (belief-state_n,-1 action_n-1, observation_n-1, belief-state_n)]\n",
        "    \"\"\"\n",
        "    p_transitions = {}\n",
        "    p_observations = {}\n",
        "    noise = numpyro.sample(f\"noise\", dist.Beta(1, 1))\n",
        "    for state,action in product(States, Actions):\n",
        "        p_transitions[(state,action)] = {}\n",
        "        for state_prime in States:\n",
        "             p_transitions[(state,action)][state_prime] = numpyro.sample(f\"T({str(state)},{str(action)},{str(state_prime)})\", dist.Beta(1, 1)) # p_transitions = {('tiger-left','open-left'): {'tiger-left': sample1,\n",
        "                                                                                                                                               #                   'tiger-right': sample2},\n",
        "                                                                                                                                               #                  ('tiger-left','open-right'): {'tiger-left': sample3,\n",
        "                                                                                                                                               #                   'tiger-right': sample4},...}\n",
        "    if obs is not None:\n",
        "        n_obs = sum(len(o) for o in obs)\n",
        "        transitions_arr = jnp.array([[list(p_transitions[state, action].values()) for state in bs] for o in obs for bs, action, _, _ in o])\n",
        "        observations_arr = jnp.array([[Observation_Model[(sp, action)][observation] for sp in belief_state_prime] for o in obs for _, _, observation, belief_state_prime in o])\n",
        "        actions = [action for o in obs for _, action, _, _ in o]\n",
        "        observations = [observation for o in obs for _, _, observation, _ in o]\n",
        "        belief_states = jnp.array([list(bs.values()) for o in obs for bs, _, _, _ in o])\n",
        "        belief_states_prime = jnp.array([list(belief_state_prime.values()) for o in obs for _, _, _, belief_state_prime in o])\n",
        "\n",
        "        calculated_bs_primes, obs_success = zip(*[\n",
        "            calc_belief_state_transition(action, p_observation, p_transition, belief_state, belief_state_prime)\n",
        "            for action, p_observation, p_transition, belief_state, belief_state_prime in zip(\n",
        "                actions, observations_arr, transitions_arr, belief_states, belief_states_prime)])\n",
        "\n",
        "        calculated_bs_primes = jnp.array(calculated_bs_primes)\n",
        "        obs_success = jnp.array(obs_success)\n",
        "\n",
        "        # with numpyro.plate(\"obs\", size=n_obs):\n",
        "        #     belief_state_prime = numpyro.sample(\"belief_state_prime\", dist.Dirichlet(concentration=jnp.ones((len(States),len(States))) * transitions_arr))\n",
        "        #     obs_bs = jnp.where(jnp.all(jnp.abs(calculated_bs_primes - belief_state_prime) <= 0.1), 1, 0)\n",
        "        #     d = observations_arr * numpyro.sample(\"d\", dist.Dirichlet(concentration=jnp.ones((2,2)) * transitions_arr)) * belief_states\n",
        "        #     weighted = observations_arr * transitions_arr * belief_states\n",
        "        #     numpyro.sample(\"o\", dist.Dirichlet(weighted), obs=belief_states_prime)\n",
        "        for i in range(n_obs):\n",
        "            n_states = len(States)\n",
        "            p_transition = transitions_arr[i]\n",
        "            p_observation = observations_arr[i]\n",
        "            belief_state = belief_states[i]\n",
        "            belief_state_prime = belief_states_prime[i]\n",
        "            weighted = p_observation * jnp.ones(n_states) * p_transition * belief_state\n",
        "            for j in range(n_states)\n",
        "                action_outcome = numpyro.sample(f\"action_outcome_{i}_{j}\", dist.Bernoulli(p_transition[i][j]))\n",
        "                success = ........\n",
        "                numpyro.sample(f\"o_{i}_{j}\", dist.Bernoulli(), obs=)\n"
      ],
      "metadata": {
        "id": "x6AjTLOEV9qk",
        "outputId": "bbee2acc-5e82-4d8a-9eaf-bca45bbff0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-8-05059175c570>, line 51)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-05059175c570>\"\u001b[0;36m, line \u001b[0;32m51\u001b[0m\n\u001b[0;31m    for j in range(n_states)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpyro.render_model(tiger_model_transition, model_args=(observations,), render_distributions=True, render_params=True,)"
      ],
      "metadata": {
        "id": "KLYDcyPCdRqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(ai_model, obs):\n",
        "    nuts_kernel = numpyro.infer.NUTS(ai_model)\n",
        "    mcmc = numpyro.infer.MCMC(\n",
        "        nuts_kernel,\n",
        "        num_warmup=500,\n",
        "        num_chains=4,\n",
        "        num_samples=5000)\n",
        "    mcmc.run(jax.random.PRNGKey(int(time.time() * 1E6)), obs=obs)\n",
        "    mcmc.print_summary()\n",
        "    return mcmc"
      ],
      "metadata": {
        "id": "o7n-4QuvQSzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(tiger_model, observations)"
      ],
      "metadata": {
        "id": "G4W0q4p5Qajy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}